# -*- coding: utf-8 -*-
"""suicide_detection_model-Bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMya-8UXxGqEqL8naZ7ktQnC0fEgTGFb
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d nikhileswarkomati/suicide-watch

!unzip Suicide_Detection.csv

#Import required libraries
import pandas as pd
import tensorflow as tf
from transformers import TFAutoModel, AutoTokenizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

import pandas as pd

# Load the dataset
df = pd.read_csv('Suicide_Detection.csv')

# Drop the first column (numbers)
df = df.iloc[:, 1:]

# Rename columns for clarity
df.columns = ['text', 'label']

# Check data
print(df.head())
print(df.info())

# Checking for data-imbalance
print(df['label'].value_counts())

# Map the labels to binary
df['label'] = df['label'].map({'suicide': 1, 'non-suicide': 0})
print(df.head())

# Split the dataset into train and test sets
train_texts, test_texts, train_labels, test_labels = train_test_split(
    df['text'], df['label'], test_size=0.2, random_state=42
)

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Tokenize the train and test texts
def tokenize(texts):
    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors="tf")

train_encodings = tokenize(train_texts)
test_encodings = tokenize(test_texts)

# Convert to TensorFlow format
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
))

test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    test_labels
))

# Creating the BERT model

class BERTForClassification(tf.keras.Model):
    def __init__(self, bert_model, num_classes):
        super().__init__()
        self.bert = bert_model
        self.fc = tf.keras.layers.Dense(num_classes, activation='sigmoid')  # Using sigmoid for binary classification

    def call(self, inputs):
        x = self.bert(inputs)[1]  # Get the pooled output
        return self.fc(x)

# Load pre-trained BERT model
bert_model = TFAutoModel.from_pretrained("bert-base-uncased")

# Create the BERT model for classification
model = BERTForClassification(bert_model, num_classes=1)

# Compile the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss=tf.keras.losses.BinaryCrossentropy(),
    metrics=['accuracy']
)

"""Have to run the model -"""

# Train the model
history = model.fit(
    train_dataset.batch(36),
    epochs=3,
    validation_data=test_dataset.batch(36)
)

# Evaluate the model on test data
test_loss, test_acc = model.evaluate(test_dataset.batch(32))
print(f"Test accuracy: {test_acc:.4f}")

# Generate predictions on test data
predictions = model.predict(test_dataset.batch(32))
pred_labels = (predictions > 0.5).astype(int)  # Convert probabilities to labels (0 or 1)

# Print the classification report
print(classification_report(test_labels, pred_labels))

model.save_pretrained("./suicide_detection_model")