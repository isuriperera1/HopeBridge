{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5sW-6ZL-w1r",
        "outputId": "cb4c00c8-b2cf-4b94-f636-e15146f376b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip files in Google Drive\n",
        "model_zip_path = '/content/drive/MyDrive/bert_suicide_model.zip'\n",
        "tokenizer_zip_path = '/content/drive/MyDrive/tokenizer (1).zip'\n",
        "\n",
        "# Directory to unzip the files\n",
        "model_dir = '/content/bert_suicide_model'\n",
        "tokenizer_dir = '/content/tokenizer (1)'\n",
        "\n",
        "# Unzip the files\n",
        "with zipfile.ZipFile(model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(model_dir)\n",
        "\n",
        "with zipfile.ZipFile(tokenizer_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(tokenizer_dir)\n",
        "\n",
        "print(\"Model and tokenizer unzipped successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXXdILqn-9oX",
        "outputId": "077b6756-46bb-4474-e3d1-4de4072b4b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer unzipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Path to the unzipped model and tokenizer in Colab\n",
        "model_name = '/content/bert_suicide_model'  # Path to the unzipped model directory\n",
        "tokenizer_name = '/content/tokenizer (1)'  # Path to the unzipped tokenizer directory\n",
        "\n",
        "# Load the TensorFlow model\n",
        "model = tf.saved_model.load(model_name)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MYJJ_NABSQ0",
        "outputId": "fac91422-b3ee-4bab-d696-897dd779ec50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making predictions.\n",
        "def test_suicide_detection(texts, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Predicts whether input texts indicate suicidal thoughts or not.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of text strings to classify.\n",
        "        model: Trained BERT classifier model.\n",
        "        tokenizer: Tokenizer used during training.\n",
        "\n",
        "    Returns:\n",
        "        None. Prints out the text and its predicted category (suicide/non-suicide).\n",
        "    \"\"\"\n",
        "    label_mapping = {0: \"non-suicide\", 1: \"suicide\"}\n",
        "\n",
        "    # Tokenize input text, including token_type_ids, and ensuring padding to the model's expected length\n",
        "    inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"tf\", return_token_type_ids=True) # Changed padding to 'max_length'\n",
        "\n",
        "    # Cast input tensors to tf.int64\n",
        "    inputs = {key: tf.cast(value, tf.int64) for key, value in inputs.items()}\n",
        "\n",
        "    # Calling function for inference\n",
        "    infer = model.signatures['serving_default']  # The inference function\n",
        "    outputs = infer(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], token_type_ids=inputs['token_type_ids']) # Added token_type_ids\n",
        "\n",
        "    # Get predictions (logits)\n",
        "    logits = outputs['output_1']\n",
        "    predictions = tf.argmax(logits, axis=1).numpy()\n",
        "\n",
        "    # Map predictions to labels\n",
        "    predicted_labels = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nPredicted Suicide Classification:\")\n",
        "    for text, label in zip(texts, predicted_labels):\n",
        "        print(f\"Text: '{text}' => Predicted Category: {label}\")\n",
        "\n",
        "# Example texts to classify\n",
        "test_texts = [\n",
        "    \"I don’t think I can do this anymore, I just want everything to stop.\",\n",
        "    \"No one would even care if I disappeared.\",\n",
        "    \"I feel so empty, like I don’t even exist.\",\n",
        "    \"I just want to sleep forever and never wake up.\",\n",
        "    \"Everything is falling apart, I can’t take it anymore.\",\n",
        "    \"I keep thinking about ways to make the pain stop.\",\n",
        "    \"I’ve lost all hope, nothing matters anymore.\",\n",
        "    \"It feels like the whole world is moving on without me.\",\n",
        "    \"I had a great time with my friends today, feeling really happy!\",\n",
        "    \"Im soooo proud about my self\",\n",
        "    \"I failed my test today, but I will try harder next time.\",\n",
        "    \"My freinds are so hillarious and I love spending time with them\",\n",
        "    \"I love going out with her, my heart is getting filled with love\",\n",
        "    \"I'm excited to start my new job next week!\",\n",
        "    \"I can't wait for the weekend, so many fun things planned!\",\n",
        "    \"What a great game today wass.. Cant believe we won\"\n",
        "]\n",
        "\n",
        "# Run the test\n",
        "test_suicide_detection(test_texts, model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1Z067dhDPeb",
        "outputId": "8c799a07-26e0-4951-daa8-8eac2bc6b36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Suicide Classification:\n",
            "Text: 'I don’t think I can do this anymore, I just want everything to stop.' => Predicted Category: suicide\n",
            "Text: 'No one would even care if I disappeared.' => Predicted Category: suicide\n",
            "Text: 'I feel so empty, like I don’t even exist.' => Predicted Category: suicide\n",
            "Text: 'I just want to sleep forever and never wake up.' => Predicted Category: suicide\n",
            "Text: 'Everything is falling apart, I can’t take it anymore.' => Predicted Category: suicide\n",
            "Text: 'I keep thinking about ways to make the pain stop.' => Predicted Category: suicide\n",
            "Text: 'I’ve lost all hope, nothing matters anymore.' => Predicted Category: suicide\n",
            "Text: 'It feels like the whole world is moving on without me.' => Predicted Category: suicide\n",
            "Text: 'I had a great time with my friends today, feeling really happy!' => Predicted Category: non-suicide\n",
            "Text: 'Im soooo proud about my self' => Predicted Category: non-suicide\n",
            "Text: 'I failed my test today, but I will try harder next time.' => Predicted Category: non-suicide\n",
            "Text: 'My freinds are so hillarious and I love spending time with them' => Predicted Category: non-suicide\n",
            "Text: 'I love going out with her, my heart is getting filled with love' => Predicted Category: non-suicide\n",
            "Text: 'I'm excited to start my new job next week!' => Predicted Category: non-suicide\n",
            "Text: 'I can't wait for the weekend, so many fun things planned!' => Predicted Category: non-suicide\n",
            "Text: 'What a great game today wass.. Cant believe we won' => Predicted Category: non-suicide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip files in Google Drive\n",
        "emt_model_zip_path = '/content/drive/MyDrive/bert_emotion_model.zip'\n",
        "\n",
        "# Directory to unzip the files\n",
        "emt_model_dir = '/content/bert_emotion_model'\n",
        "\n",
        "# Unzip the files\n",
        "with zipfile.ZipFile(emt_model_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(emt_model_dir)\n",
        "\n",
        "print(\"Emotion Model unzipped successfully!\")"
      ],
      "metadata": {
        "id": "zt_Sna_uHewI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd00c5fb-f821-439d-c3cd-b72c3314d114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion Model unzipped successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Path to the unzipped model and tokenizer in Colab\n",
        "emt_model_name = '/content/bert_emotion_model'  # Path to the unzipped model directory\n",
        "\n",
        "# Load the TensorFlow model\n",
        "emt_model = tf.saved_model.load(emt_model_name)\n",
        "\n",
        "print(\"Emotion Model loaded successfully!\")"
      ],
      "metadata": {
        "id": "WpO6_JmEHi92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b9dfff-df72-4d9d-a488-5b318ed6d76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def test_emotion_detection(texts, emt_model, tokenizer, label_mapping):\n",
        "    \"\"\"\n",
        "    Predicts the emotion of input texts.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of text strings to classify.\n",
        "        emt_model: Trained BERT emotion classifier model.\n",
        "        tokenizer: Tokenizer used during training.\n",
        "        label_mapping (dict): Dictionary mapping label indices to emotion labels.\n",
        "\n",
        "    Returns:\n",
        "        None. Prints out the text and its predicted emotion.\n",
        "    \"\"\"\n",
        "    # Tokenize input text, ensuring padding and truncation\n",
        "    # Change max_length to 87 to match the model's expected input shape\n",
        "    inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=87, return_tensors=\"tf\", return_token_type_ids=True)\n",
        "\n",
        "    # Cast input tensors to tf.int64\n",
        "    inputs = {key: tf.cast(value, tf.int64) for key, value in inputs.items()}\n",
        "\n",
        "    # Run inference using the model\n",
        "    infer = emt_model.signatures['serving_default']\n",
        "    outputs = infer(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], token_type_ids=inputs['token_type_ids'])\n",
        "\n",
        "    # Get predictions\n",
        "    logits = outputs['output_1']\n",
        "    predictions = tf.argmax(logits, axis=1).numpy()\n",
        "\n",
        "    # Map predictions to emotion labels\n",
        "    predicted_emotions = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nPredicted Emotions:\")\n",
        "    for text, emotion in zip(texts, predicted_emotions):\n",
        "        print(f\"Text: '{text}' => Predicted Emotion: {emotion}\")\n",
        "\n",
        "# Example texts to classify\n",
        "test_texts = [\n",
        "    \"I am so excited for my birthday party tomorrow!\",\n",
        "    \"I feel so angry, they always take me for granted!\",\n",
        "    \"Tired of crying my eyes out every night\",\n",
        "    \"I think I might be falling in love, they make me so happy!\",\n",
        "    \"Why is everyone against me? I feel so betrayed.\",\n",
        "    \"Today was one of the best days ever, I feel amazing!\",\n",
        "    \"I hate when people lie to me, it makes me so mad.\",\n",
        "    \"I’m so nervous about my final exams, I hope I do well.\",\n",
        "    \"I can’t stop smiling, today was just perfect!\",\n",
        "    \"I feel like crying, everything is going wrong.\",\n",
        "    \"Wow, I can’t believe I actually did it! So proud of myself.\",\n",
        "    \"I’m shaking, that horror movie scared me so much!\",\n",
        "    \"I just feel so alone even when I’m surrounded by people.\",\n",
        "    \"I finally got the job! I can’t believe it, I’m so happy!\",\n",
        "    \"Ugh, traffic was so bad today, I was so annoyed.\",\n",
        "    \"I feel so peaceful watching the sunset, it’s beautiful.\"\n",
        "]\n",
        "\n",
        "# Define the label mapping\n",
        "label_mapping = {\n",
        "    1: \"joy\",\n",
        "    3: \"anger\",\n",
        "    0: \"sadness\",\n",
        "    5: \"surprise\",\n",
        "    2: \"love\",\n",
        "    4: \"fear\"\n",
        "}\n",
        "\n",
        "# Run the test on the emotion model\n",
        "test_emotion_detection(test_texts, emt_model, tokenizer, label_mapping)"
      ],
      "metadata": {
        "id": "e7fQ1vmZNJfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b7032c-52b6-489f-d423-24146cd39470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Emotions:\n",
            "Text: 'I am so excited for my birthday party tomorrow!' => Predicted Emotion: joy\n",
            "Text: 'I feel so angry, they always take me for granted!' => Predicted Emotion: anger\n",
            "Text: 'Tired of crying my eyes out every night' => Predicted Emotion: sadness\n",
            "Text: 'I think I might be falling in love, they make me so happy!' => Predicted Emotion: joy\n",
            "Text: 'Why is everyone against me? I feel so betrayed.' => Predicted Emotion: sadness\n",
            "Text: 'Today was one of the best days ever, I feel amazing!' => Predicted Emotion: surprise\n",
            "Text: 'I hate when people lie to me, it makes me so mad.' => Predicted Emotion: anger\n",
            "Text: 'I’m so nervous about my final exams, I hope I do well.' => Predicted Emotion: fear\n",
            "Text: 'I can’t stop smiling, today was just perfect!' => Predicted Emotion: joy\n",
            "Text: 'I feel like crying, everything is going wrong.' => Predicted Emotion: fear\n",
            "Text: 'Wow, I can’t believe I actually did it! So proud of myself.' => Predicted Emotion: joy\n",
            "Text: 'I’m shaking, that horror movie scared me so much!' => Predicted Emotion: fear\n",
            "Text: 'I just feel so alone even when I’m surrounded by people.' => Predicted Emotion: sadness\n",
            "Text: 'I finally got the job! I can’t believe it, I’m so happy!' => Predicted Emotion: joy\n",
            "Text: 'Ugh, traffic was so bad today, I was so annoyed.' => Predicted Emotion: anger\n",
            "Text: 'I feel so peaceful watching the sunset, it’s beautiful.' => Predicted Emotion: joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def detect_suicide_and_emotion(texts, model, emt_model, tokenizer, label_mapping):\n",
        "    \"\"\"\n",
        "    First detects if the text contains suicidal thoughts.\n",
        "    If no suicide risk is detected, it then predicts the emotion of the text.\n",
        "\n",
        "    Args:\n",
        "        texts (list): List of text strings to classify.\n",
        "        suicide_model: Trained BERT suicide detection model.\n",
        "        emotion_model: Trained BERT emotion classification model.\n",
        "        tokenizer: Tokenizer used during training.\n",
        "        emotion_label_mapping (dict): Dictionary mapping label indices to emotion labels.\n",
        "\n",
        "    Returns:\n",
        "        None. Prints out the text and its detected category (suicide/non-suicide) and emotion.\n",
        "    \"\"\"\n",
        "    suicide_label_mapping = {0: \"non-suicide\", 1: \"suicide\"}\n",
        "\n",
        "    risk_levels = {\"sadness\": \"Medium Risk\", \"anger\": \"Medium Risk\", \"fear\": \"Medium Risk\"}\n",
        "\n",
        "    # Process each text individually to handle different tokenization lengths\n",
        "    for text in texts:\n",
        "        # Tokenize input text for suicide detection\n",
        "        inputs_suicide = tokenizer([text], padding='max_length', truncation=True, max_length=128, return_tensors=\"tf\", return_token_type_ids=True)\n",
        "        inputs_suicide = {key: tf.cast(value, tf.int64) for key, value in inputs_suicide.items()}\n",
        "\n",
        "        # Run suicide detection model\n",
        "        infer_suicide = model.signatures['serving_default']\n",
        "        suicide_outputs = infer_suicide(input_ids=inputs_suicide['input_ids'], attention_mask=inputs_suicide['attention_mask'], token_type_ids=inputs_suicide['token_type_ids'])\n",
        "\n",
        "        # Extract logits and make predictions\n",
        "        suicide_logits = suicide_outputs['output_1']\n",
        "        suicide_prediction = tf.argmax(suicide_logits, axis=1).numpy()[0]  # Get prediction for the single text\n",
        "\n",
        "        suicide_label = suicide_label_mapping[suicide_prediction]\n",
        "\n",
        "        if suicide_label == \"suicide\":\n",
        "            print(f\"Text: '{text}' => High Risk\")\n",
        "        else:\n",
        "            # Tokenize input text for emotion detection with correct max_length\n",
        "            inputs_emotion = tokenizer([text], padding='max_length', truncation=True, max_length=87, return_tensors=\"tf\", return_token_type_ids=True)\n",
        "            inputs_emotion = {key: tf.cast(value, tf.int64) for key, value in inputs_emotion.items()}\n",
        "\n",
        "            # If no suicide risk, proceed with emotion detection\n",
        "            infer_emotion = emt_model.signatures['serving_default']\n",
        "            emotion_outputs = infer_emotion(input_ids=inputs_emotion['input_ids'], attention_mask=inputs_emotion['attention_mask'], token_type_ids=inputs_emotion['token_type_ids'])\n",
        "\n",
        "            # Get predictions\n",
        "            emotion_logits = emotion_outputs['output_1']\n",
        "            emotion_prediction = tf.argmax(emotion_logits, axis=1).numpy()[0]  # Get prediction for the single text\n",
        "\n",
        "            # Map prediction to emotion label\n",
        "            emotion_label = label_mapping[emotion_prediction]\n",
        "\n",
        "            # Determine risk level\n",
        "            risk_level = risk_levels.get(emotion_label, \"Low Risk\")\n",
        "\n",
        "            print(f\"Text: '{text}' => **Emotion:** {emotion_label} => **{risk_level}**\")\n",
        "\n",
        "# Example texts to classify\n",
        "test_texts = [\n",
        "    \"I don’t know what’s wrong with me, I feel empty all the time.\",\n",
        "    \"I love my best friend so much, they always make me smile.\",\n",
        "    \"It’s been a terrible day, I feel like I just want to disappear.\",\n",
        "    \"I can’t stop crying, why does life have to be this hard?\",\n",
        "    \"aww shes so cute.. todays date was amazinggg.\",\n",
        "    \"I’m scared that things will never get better for me.\",\n",
        "    \"I had so much fun at the party tonight, best night ever!\",\n",
        "    \"I feel like I’m stuck in a loop, nothing ever changes.\",\n",
        "    \"I was so sad, Cried alot when I first got to know that\",\n",
        "    \"I finally spoke up about my problems, I hope things change.\",\n",
        "    \"I can’t stop thinking about how much I hate myself.\",\n",
        "    \"I had the best day with my friends, I feel so loved!\",\n",
        "    \"I feel so lost, I don’t even know what I want anymore.\",\n",
        "    \"I wish someone could understand how much I’m struggling.\",\n",
        "    \"I was so anxious about my test, but I think I did well.\",\n",
        "    \"I laughed so hard todayyy.. my friends are so hillarious\"\n",
        "]\n",
        "\n",
        "\n",
        "# Define the emotion label mapping\n",
        "label_mapping = {\n",
        "    0: \"sadness\",\n",
        "    1: \"joy\",\n",
        "    2: \"love\",\n",
        "    3: \"anger\",\n",
        "    4: \"fear\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "\n",
        "# Run the detection function\n",
        "detect_suicide_and_emotion(test_texts, model, emt_model, tokenizer, label_mapping)\n"
      ],
      "metadata": {
        "id": "uPq6kkc_Qon9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064e1931-cab1-4ed5-f32f-1dc0adddf1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'I don’t know what’s wrong with me, I feel empty all the time.' => High Risk\n",
            "Text: 'I love my best friend so much, they always make me smile.' => **Emotion:** love => **Low Risk**\n",
            "Text: 'It’s been a terrible day, I feel like I just want to disappear.' => High Risk\n",
            "Text: 'I can’t stop crying, why does life have to be this hard?' => High Risk\n",
            "Text: 'aww shes so cute.. todays date was amazinggg.' => **Emotion:** joy => **Low Risk**\n",
            "Text: 'I’m scared that things will never get better for me.' => High Risk\n",
            "Text: 'I had so much fun at the party tonight, best night ever!' => **Emotion:** joy => **Low Risk**\n",
            "Text: 'I feel like I’m stuck in a loop, nothing ever changes.' => High Risk\n",
            "Text: 'I was so sad, Cried alot when I first got to know that' => **Emotion:** sadness => **Medium Risk**\n",
            "Text: 'I finally spoke up about my problems, I hope things change.' => High Risk\n",
            "Text: 'I can’t stop thinking about how much I hate myself.' => High Risk\n",
            "Text: 'I had the best day with my friends, I feel so loved!' => **Emotion:** love => **Low Risk**\n",
            "Text: 'I feel so lost, I don’t even know what I want anymore.' => High Risk\n",
            "Text: 'I wish someone could understand how much I’m struggling.' => High Risk\n",
            "Text: 'I was so anxious about my test, but I think I did well.' => **Emotion:** fear => **Medium Risk**\n",
            "Text: 'I laughed so hard todayyy.. my friends are so hillarious' => **Emotion:** joy => **Low Risk**\n"
          ]
        }
      ]
    }
  ]
}