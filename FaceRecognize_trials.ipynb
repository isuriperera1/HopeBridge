{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz6k7fCYbCRnUECE5WmGN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isuriperera1/HopeBridge/blob/Face-Recognition/FaceRecognize_trials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d5gbwSk8PDp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = 'face_model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Display the model summary to verify input shape\n",
        "model.summary()\n",
        "\n",
        "# Load and preprocess an image\n",
        "def preprocess_image(image_path, target_size):\n",
        "    # Ensure the input matches the model's expected shape\n",
        "    image = load_img(image_path, target_size=target_size, color_mode='rgb')  # Change 'grayscale' to 'rgb' if required\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "    image_array /= 255.0  # Normalize the image\n",
        "    return image_array\n",
        "\n",
        "# Example: Provide the path to your test image\n",
        "image_path = 'image.jpeg'  # Replace with your image path\n",
        "\n",
        "# Adjust the target size as per the model's input\n",
        "target_size = (224, 224)  # Update based on the model input shape\n",
        "image = preprocess_image(test_image_path, target_size=target_size)\n",
        "\n",
        "# Ensure compatibility with model input\n",
        "predictions = model.predict(image)\n",
        "print(\"Predictions:\", predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoImageProcessor, AutoModel\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "model = AutoModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "def preprocess_image(image_path, target_size):\n",
        "    image = load_img(image_path, target_size=target_size)  # Resize the image\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    image_array = np.expand_dims(image_array, axis=-1)  # Add channel dimension\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "    image_array /= 255.0  # Normalize the image\n",
        "    return image_array\n",
        "\n",
        "# Example: Provide the path to your test image\n",
        "test_image_path = 'image.jpeg'  # Replace with your image path\n",
        "image = preprocess_image(test_image_path, target_size=(48, 48))  # Resize to 48x48\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(image)[0]  # Get the first prediction from the batch\n",
        "\n",
        "# Get the emotion with the highest probability\n",
        "predicted_emotion = emotion_labels[np.argmax(predictions)]\n",
        "\n",
        "# Display the result\n",
        "print(predicted_emotion)\n"
      ],
      "metadata": {
        "id": "TKk5P8nL8dyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow"
      ],
      "metadata": {
        "id": "VwRz0gLj8u3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inference_sdk import InferenceHTTPClient\n",
        "\n",
        "CLIENT = InferenceHTTPClient(\n",
        "    api_url=\"https://detect.roboflow.com\",\n",
        "    api_key=\"API_KEY\"\n",
        ")\n",
        "\n",
        "result = CLIENT.infer(image.jpg, model_id=\"facial-emotion-recognition/2\")"
      ],
      "metadata": {
        "id": "zLPZ7JF-8yOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import io\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "def detect_face(image_path):\n",
        "    \"\"\"Detects faces in an image and draws bounding boxes around them.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input image file.\n",
        "\n",
        "    Returns:\n",
        "        The image with detected faces, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    # Load the pre-trained Haar Cascade classifier for face detection\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error loading image\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected\")\n",
        "        return img\n",
        "\n",
        "    # Draw rectangle around faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    # Save and show the image with the face detected\n",
        "    output_path = 'output_image.jpg'\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    # Convert the image to RGB format for display in the notebook\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the output using PIL and IPython.display\n",
        "    display(Image.fromarray(img_rgb))\n",
        "\n",
        "    return img, True  # Face detected\n",
        "\n",
        "def handle_upload(change):\n",
        "    \"\"\"Handles the uploaded image.\n",
        "\n",
        "    Args:\n",
        "        change: The change event.\n",
        "    \"\"\"\n",
        "    uploaded_filename = next(iter(change['new']))\n",
        "    content = change['new'][uploaded_filename]['content']\n",
        "    # Process the uploaded image\n",
        "    with io.BytesIO(content) as f:\n",
        "        f.seek(0)  # Reset file pointer to the beginning\n",
        "        image = Image.open(f)\n",
        "        image.save(\"uploaded_image.jpg\")  # Save the image to a temporary file\n",
        "        detect_face(\"uploaded_image.jpg\")  # Call detect_face on the temporary file\n",
        "\n",
        "\n",
        "# Create an upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accepted file types\n",
        "    multiple=False  # Only allow single file upload\n",
        ")\n",
        "\n",
        "# Display the upload widget and attach the handler\n",
        "display(uploader)\n",
        "uploader.observe(handle_upload, names='value')  # Observe changes in the 'value' property"
      ],
      "metadata": {
        "id": "NwG-DrYl89YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = 'FR_Model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "# Load and preprocess an image\n",
        "def preprocess_image(image_path, target_size):\n",
        "    image = load_img(image_path, target_size=target_size)  # Resize the image\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    image_array = np.expand_dims(image_array, axis=-1)  # Add channel dimension\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "    image_array /= 255.0  # Normalize the image\n",
        "    return image_array\n",
        "\n",
        "# Example: Provide the path to your test image\n",
        "test_image_path = 'image.jpeg'  # Replace with your image path\n",
        "image = preprocess_image(test_image_path, target_size=(48, 48))  # Resize to 48x48\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(image)[0]  # Get the first prediction from the batch\n",
        "\n",
        "# Visualize the scores in a pie chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(predictions, labels=emotion_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab10.colors)\n",
        "plt.title('Emotion Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kjlXTTtL9IgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = 'FR_Model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "# Load and preprocess an image\n",
        "def preprocess_image(image_path, target_size):\n",
        "    image = load_img(image_path, target_size=target_size)  # Resize the image\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    image_array = np.expand_dims(image_array, axis=-1)  # Add channel dimension\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "    image_array /= 255.0  # Normalize the image\n",
        "    return image_array\n",
        "\n",
        "\n",
        "# Function to handle uploaded image\n",
        "def handle_upload(change):\n",
        "    uploaded_filename = next(iter(change['new']))\n",
        "    content = change['new'][uploaded_filename]['content']\n",
        "    # Process the uploaded image\n",
        "    with io.BytesIO(content) as f:\n",
        "        image_path = f\n",
        "        # Preprocess the selected image\n",
        "        image = preprocess_image(image_path, target_size=(48, 48))  # Resize to 48x48\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(image)[0]  # Get the first prediction from the batch\n",
        "\n",
        "        # Visualize the scores in a pie chart\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.pie(predictions, labels=emotion_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab10.colors)\n",
        "        plt.title('Emotion Scores')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create an upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accepted file types\n",
        "    multiple=False  # Only allow single file upload\n",
        ")\n",
        "\n",
        "# Display the upload widget and attach the handler\n",
        "display(uploader)\n",
        "uploader.observe(handle_upload, names='value')  # Observe changes in the 'value' property"
      ],
      "metadata": {
        "id": "veqPc46q9VUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Load the pre-trained model\n",
        "model_path = 'FR_Model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "# Load and preprocess an image\n",
        "def preprocess_image(image, target_size):\n",
        "    image = image.resize(target_size)  # Resize the image\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    image_array = np.expand_dims(image_array, axis=-1)  # Add channel dimension\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "    image_array /= 255.0  # Normalize the image\n",
        "    return image_array\n",
        "\n",
        "\n",
        "# Function to handle uploaded image\n",
        "def handle_upload(change):\n",
        "    \"\"\"Handles the uploaded image.\n",
        "\n",
        "    Args:\n",
        "        change: The change event.\n",
        "    \"\"\"\n",
        "    uploaded_filename = next(iter(change['new']))\n",
        "    content = change['new'][uploaded_filename]['content']\n",
        "    # Process the uploaded image\n",
        "    with io.BytesIO(content) as f:\n",
        "        # Load the image using PIL\n",
        "        image = load_img(f)\n",
        "        # Preprocess the selected image\n",
        "        image = preprocess_image(image, target_size=(48, 48))  # Resize to 48x48\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(image)[0]  # Get the first prediction from the batch\n",
        "\n",
        "        # Visualize the scores in a pie chart\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.pie(predictions, labels=emotion_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab10.colors)\n",
        "        plt.title('Emotion Scores')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create an upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accepted file types\n",
        "    multiple=False  # Only allow single file upload\n",
        ")\n",
        "\n",
        "# Display the upload widget and attach the handler\n",
        "display(uploader)\n",
        "uploader.observe(handle_upload, names='value')  # Observe changes in the 'value' property"
      ],
      "metadata": {
        "id": "6NEZwyDL9dcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import io\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the pre-trained model for emotion detection\n",
        "model_path = 'FR_Model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "# Load and preprocess image for emotion detection\n",
        "def preprocess_image(image_path, target_size):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "    image_array = np.expand_dims(image_array, axis=-1)\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    image_array /= 255.0\n",
        "    return image_array\n",
        "\n",
        "# Detect faces in the image\n",
        "def detect_face(image_path):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error loading image\")\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected\")\n",
        "        # Instead of returning img, still return the path\n",
        "        # cv2.imwrite will have saved the image even if no faces were detected\n",
        "        output_path = 'output_image.jpg'\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert for display\n",
        "        display(Image.fromarray(img_rgb))\n",
        "        return output_path\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    output_path = 'output_image.jpg'\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    display(Image.fromarray(img_rgb))\n",
        "\n",
        "    return output_path  # Return path of the image with detected faces\n",
        "\n",
        "# Handle uploaded image for both face detection and emotion detection\n",
        "def handle_upload(change):\n",
        "    uploaded_filename = next(iter(change['new']))\n",
        "    content = change['new'][uploaded_filename]['content']\n",
        "\n",
        "    # Process the uploaded image\n",
        "    with io.BytesIO(content) as f:\n",
        "        f.seek(0)\n",
        "        image = Image.open(f)\n",
        "        image.save(\"uploaded_image.jpg\")\n",
        "\n",
        "    # Detect face and get the path to the processed image\n",
        "    face_image_path = detect_face(\"uploaded_image.jpg\")\n",
        "\n",
        "    # Preprocess the image for emotion detection\n",
        "    image = preprocess_image(face_image_path, target_size=(48, 48))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(image)[0]\n",
        "\n",
        "    # Visualize the emotion scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.pie(predictions, labels=emotion_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab10.colors)\n",
        "    plt.title('Emotion Scores')\n",
        "    plt.show()\n",
        "\n",
        "# Create an upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "# Display the upload widget and attach the handler\n",
        "display(uploader)\n",
        "uploader.observe(handle_upload, names='value')\n"
      ],
      "metadata": {
        "id": "vMwwwJk19lDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_depression_level(emotion_scores, emotion_labels):\n",
        "    # Define groups\n",
        "    negative_emotions = ['Angry', 'Disgust', 'Fear', 'Sad']\n",
        "    positive_emotions = ['Happy', 'Surprise']\n",
        "    neutral_emotion = ['Neutral']\n",
        "\n",
        "    # Aggregate scores\n",
        "    negative_score = sum(emotion_scores[emotion_labels.index(e)] for e in negative_emotions)\n",
        "    positive_score = sum(emotion_scores[emotion_labels.index(e)] for e in positive_emotions)\n",
        "    neutral_score = emotion_scores[emotion_labels.index('Neutral')]\n",
        "\n",
        "    # Weighted depression score\n",
        "    depression_score = (negative_score * 0.6) + (neutral_score * 0.3) - (positive_score * 0.1)\n",
        "\n",
        "    # Define thresholds for depression levels\n",
        "    if depression_score < 0.4:\n",
        "        return \"Low\"\n",
        "    elif 0.4 <= depression_score < 0.7:\n",
        "        return \"Moderate\"\n",
        "    else:\n",
        "        return \"High\"\n",
        "\n",
        "# Example usage with predictions\n",
        "depression_level = detect_depression_level(predictions, emotion_labels)\n",
        "print(f\"Depression Level: {depression_level}\")\n"
      ],
      "metadata": {
        "id": "linTAjKXBBKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import io\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the pre-trained model for emotion detection\n",
        "model_path = 'FR_Model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Emotion labels\n",
        "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "# Load and preprocess image for emotion detection\n",
        "def preprocess_image(image_path, target_size):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
        "    image_array = np.expand_dims(image_array, axis=-1)\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    image_array /= 255.0\n",
        "    return image_array\n",
        "\n",
        "# Detect faces in the image\n",
        "def detect_face(image_path):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error loading image\")\n",
        "        return None\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        print(\"No faces detected\")\n",
        "        # Display the message instead of proceeding to the next step\n",
        "        output_path = 'output_image.jpg'\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert for display\n",
        "        display(Image.fromarray(img_rgb))\n",
        "        return None  # Stop the process if no face is detected\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    output_path = 'output_image.jpg'\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    display(Image.fromarray(img_rgb))\n",
        "\n",
        "    return output_path  # Return path of the image with detected faces\n",
        "\n",
        "# Handle uploaded image for both face detection and emotion detection\n",
        "def handle_upload(change):\n",
        "    uploaded_filename = next(iter(change['new']))\n",
        "    content = change['new'][uploaded_filename]['content']\n",
        "\n",
        "    # Process the uploaded image\n",
        "    with io.BytesIO(content) as f:\n",
        "        f.seek(0)\n",
        "        image = Image.open(f)\n",
        "        image.save(\"uploaded_image.jpg\")\n",
        "\n",
        "    # Detect face and get the path to the processed image\n",
        "    face_image_path = detect_face(\"uploaded_image.jpg\")\n",
        "\n",
        "    # If no face is detected, stop further processing\n",
        "    if face_image_path is None:\n",
        "        return  # Exit the function if no face was detected\n",
        "\n",
        "    # Preprocess the image for emotion detection\n",
        "    image = preprocess_image(face_image_path, target_size=(48, 48))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(image)[0]\n",
        "\n",
        "    # Visualize the emotion scores\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.pie(predictions, labels=emotion_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab10.colors)\n",
        "    plt.title('Emotion Scores')\n",
        "    plt.show()\n",
        "\n",
        "# Create an upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "# Display the upload widget and attach the handler\n",
        "display(uploader)\n",
        "uploader.observe(handle_upload, names='value')\n"
      ],
      "metadata": {
        "id": "gVyUlVM4BHhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}